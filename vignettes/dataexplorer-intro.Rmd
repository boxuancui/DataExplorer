---
title: "Introduction to DataExplorer"
author: "Boxuan Cui"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to DataExplorer}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r setup, include=FALSE}
library(rmarkdown)
library(knitr)
library(DataExplorer)
library(data.table)
library(ggplot2)
library(nycflights13)
library(networkD3)

opts_chunk$set(
	collapse = TRUE,
	comment = "#>",
	fig.width = 6,
	fig.height = 6,
	fig.align = "center",
	warning = FALSE
)
```

<script src="d3.min.js"></script>

This document introduces the package **DataExplorer**, and shows how it can help you with different tasks throughout your data exploration process.

There are 3 main goals for **DataExplorer**:

1. [Exploratory Data Analysis (EDA)](https://en.wikipedia.org/wiki/Exploratory_data_analysis)
1. [Feature Engineering](https://en.wikipedia.org/wiki/Feature_engineering)
1. Data Reporting

The remaining of this guide will be organized in accordance with the goals. As the package evolves, more content will be added.

## Data
We will be using the [nycflights13](https://cran.r-project.org/package=nycflights13) datasets for this document. If you have not installed the package, please do the following:

```{r install-data, eval=FALSE}
install.packages("nycflights13")
library(nycflights13)
```

There are 5 datasets in this package:

* airlines
* airports
* flights
* planes
* weather

If you want to quickly visualize the structure of all, you may do the following:

```{r plot-str-template, eval=FALSE}
library(DataExplorer)
data_list <- list(airlines, airports, flights, planes, weather)
plot_str(data_list)
```

```{r plot-str-run, echo=FALSE}
data_list <- list(airlines, airports, flights, planes, weather)
diagonalNetwork(
	plot_str(data_list, print_network = FALSE),
	width = 800,
	height = 800,
	fontSize = 20,
	margin = list(
		"left" = 50,
		"right" = 50
	)
)
```

You may also try `plot_str(data_list, type = "r")` for a radial network.

---

Now let's merge all tables together for a more robust dataset for later sections.

```{r merge-data}
merge_airlines <- merge(flights, airlines, by = "carrier", all.x = TRUE)
merge_planes <- merge(merge_airlines, planes, by = "tailnum", all.x = TRUE, suffixes = c("_flights", "_planes"))
merge_airports_origin <- merge(merge_planes, airports, by.x = "origin", by.y = "faa", all.x = TRUE, suffixes = c("_carrier", "_origin"))
final_data <- merge(merge_airports_origin, airports, by.x = "dest", by.y = "faa", all.x = TRUE, suffixes = c("_origin", "_dest"))
```

## Exploratory Data Analysis
Exploratory data analysis is the process to get to know your data, so that you can generate and test your hypothesis. Visualization techniques are usually applied.

To get introduced to your newly created dataset:

```{r eda-introduce-template, eval=FALSE}
introduce(final_data)
```

```{r eda-introduce-run, echo=FALSE}
kable(introduce(final_data), format.args = list(big.mark = ","))
```

### Missing values
Real-world data is messy. After running the basic descriptive statistics, you might be interested in the missing data profile. You can simply use `plot_missing` function for this.

```{r eda-plot-missing}
plot_missing(final_data)
```

Looks like **speed** variable is mostly missing, and probably not informative. Let's drop it:

```{r eda-drop-speed}
final_data <- drop_columns(final_data, "speed")
```

You may also store the missing data profile with `profile_missing(final_data)` for additional analysis.

### Distributions
#### Bar Charts
To visualize frequency distributions for all discrete features:

```{r eda-plot-bar-template, eval=FALSE}
plot_bar(final_data)
```

```{r eda-plot-bar-run, echo=FALSE, fig.width=10, fig.height=6}
plot_bar(final_data, theme_config = list("text" = element_text(size = 4)))
```

Upon closer inspection of **manufacturer** variable, it is not hard to identify the following duplications:

* *AIRBUS* and *AIRBUS INDUSTRIE*
* *CANADAIR* and *CANADAIR LTD*
* *MCDONNELL DOUGLAS*, *MCDONNELL DOUGLAS AIRCRAFT CO* and *MCDONNELL DOUGLAS CORPORATION*

Let's clean it up and look at the **manufacturer** distribution again:

```{r eda-update-manufacturer}
final_data[which(final_data$manufacturer == "AIRBUS INDUSTRIE"),]$manufacturer <- "AIRBUS"
final_data[which(final_data$manufacturer == "CANADAIR LTD"),]$manufacturer <- "CANADAIR"
final_data[which(final_data$manufacturer %in% c("MCDONNELL DOUGLAS AIRCRAFT CO", "MCDONNELL DOUGLAS CORPORATION")),]$manufacturer <- "MCDONNELL DOUGLAS"

plot_bar(final_data$manufacturer)
```

Feature **dst_origin** and **tzone_origin** contains only 1 value, so we should drop them:

```{r eda-drop-bar-features}
final_data <- drop_columns(final_data, c("dst_origin", "tzone_origin"))
```


Frequently, it is very beneficial to look at bivariate frequency distribution. For example, to look at discrete features by **arr_delay**:

```{r eda-plot-bar-with-template, eval=FALSE}
plot_bar(final_data, with = "arr_delay")
```

```{r eda-plot-bar-with-run, echo=FALSE, fig.width=10, fig.height=6}
plot_bar(final_data, with = "arr_delay", theme_config = list("text" = element_text(size = 4)))
```

The resulting distribution looks quite different from the regular frequency distribution.

#### Histograms
To visualize distributions for all continuous features:

```{r eda-plot-histogram, fig.width=10, fig.height=6}
suppressWarnings(plot_histogram(final_data))
```

Immediately, you could observe that there are datetime features to be further treated, e.g., concatenating year, month and day to form date, and/or adding hour and minute to form datetime.

For the purpose of this vignette, I will not go deep into the analytical tasks. However, we should treat the following features based on the output of the histograms.

* Set **flight** to categorical, since that is the flight number with no mathematical meaning:
```{r eda-update-flight}
final_data$flight <- as.factor(final_data$flight)
```

* Remove **year_flights** and **tz_origin** since there is only one value:
```{r eda-drop-histogram-features}
final_data <- drop_columns(final_data, c("year_flights", "tz_origin"))
```

### Correlation Analysis
To visualize correlation heatmap for all non-missing features:

```{r eda-plot-correlation, fig.width=8, fig.height=8}
plot_correlation(na.omit(final_data), maxcat = 5L)
```

You may also choose to visualize only discrete/continuous features with:

```{r eda-plot-correlation-type, eval=FALSE}
plot_correlation(na.omit(final_data), type = "c")
plot_correlation(na.omit(final_data), type = "d")
```

### Principle Component Analysis
While you can always do `plot_prcomp(na.omit(final_data))` directly, but PCA works better with cleaner data. To perform and visualize PCA on some selected features:

```{r eda-plot-prcomp}
pca_df <- na.omit(final_data[, c("origin", "name_carrier", "type", "engine", "dep_delay", "arr_delay", "air_time", "month", "hour", "year_planes", "seats")])

plot_prcomp(pca_df)
```

### Slicing & dicing
Often, slicing and dicing data in different ways could be crucial to your analysis, and yields insights quickly.

#### Boxplots
Suppose you would like to build a model to predict arrival delays, you may visualize the distribution of all continuous features based on arrival delays with a boxplot:

```{r eda-plot-boxplot, fig.width=8, fig.height=8}
## Reduce data size for demo purpose
arr_delay_df <- final_data[, c("arr_delay", "month", "day", "hour", "minute", "dep_delay", "distance", "year_planes", "seats")]

## Call boxplot function
plot_boxplot(arr_delay_df, by = "arr_delay")
```

Among all the subtle changes in correlation with arrival delays, you could immediately spot that planes with 300+ seats tend to have much longer delays (16 ~ 21 hours). You may now drill down further to verify or generate more hypotheses.

#### Scatterplots
An alternative visualization is scatterplot. For example:

```{r eda-plot-scatterplot, fig.width=8, fig.height=8}
## Reduce data size for demo purpose
arr_delay_df2 <- final_data[sample.int(nrow(final_data), 1000), c("arr_delay", "dep_time", "dep_delay", "arr_time", "air_time", "distance", "year_planes", "seats")]

## Call scatterplot function
plot_scatterplot(arr_delay_df2, by = "arr_delay", size = 0.5)
```

## Feature Engineering
Feature engineering is the process of creating new features from existing ones. Newly engineered features often generate valuable insights.

For functions in this section, it is preferred to use [data.table](https://cran.r-project.org/package=data.table) objects as input, and they will be [updated by reference](https://cran.r-project.org/package=data.table/vignettes/datatable-reference-semantics.html). Otherwise, output object will be returned matching the input class.

### Replace missing values
Missing values may have meanings for a feature. Other than imputation methods, we may also set them to some logical values. For example, for discrete features, we may want to group missing values to a new category. For continuous features, we may want to set missing values to a known number based on existing knowledge.

In **DataExplorer**, this can be done by `set_missing`. The function automatically matches the argument for either discrete or continuous features, i.e., if you specify a number, all missing continuous values will be set to that number. If you specify a string, all missing discrete values will be set to that string. If you supply both, both types will be set.

```{r fe-set-missing, collapse=TRUE}
## Return data.frame
final_df <- set_missing(final_data, list(0L, "unknown"))
plot_missing(final_df)

## Update data.table by reference
# library(data.table)
# final_dt <- data.table(final_data)
# set_missing(final_dt, list(0L, "unknown"))
# plot_missing(final_dt)
```

### Group sparse categories
From the bar charts above, we observed a number of discrete features with sparse categorical distributions. Sometimes, we want to group low-frequency categories to a new bucket, or reduce the number of categories to a reasonable range. `group_category` will do the work.

Take **manufacturer** feature for example, suppose we want to group the long tail to another category. We could try with bottom 20% (by count) first:

```{r fe-group-category-count-trial}
group_category(data = final_data, feature = "manufacturer", threshold = 0.2)
```

As we can see, manufacturer will be shrinked down to 4 categories, i.e., AIRBUS, BOEING, EMBRAER, and OTHER. If you like this threshold, you may specify `update = TRUE` to update the original dataset:

```{r fe-group-category-count-update, results='hide'}
final_df <- group_category(data = final_data, feature = "manufacturer", threshold = 0.2, update = TRUE)
plot_bar(final_df$manufacturer)
```

Instead of shrinking categories by frequency, you may also group the categories by another continuous metric. For example, if you want to bucket the carrier with bottom 20% distance traveled, you may do the following:

```{r fe-group-category-metric-trial}
group_category(data = final_data, feature = "name_carrier", threshold = 0.2, measure = "distance")
```

Similarly, if you like it, you may add `update = TRUE` to update the original dataset.

```{r fe-group-category-metric-update, results='hide'}
final_df <- group_category(data = final_data, feature = "name_carrier", threshold = 0.2, measure = "distance", update = TRUE)
plot_bar(final_df$name_carrier)
```

### Dummify data (one hot encoding)
To transform the data into binary format (so that ML algorithms can pick it up), `dummify` will do the job. The function preserves original data structure, so that only eligible discrete features will be turned into binary format.

```{r fe-dummify-template, eval=FALSE}
plot_str(
	list(
		"original" = final_data,
		"dummified" = dummify(final_data, maxcat = 5L)
	)
)
```

```{r fe-dummify-run, echo=FALSE}
diagonalNetwork(
	plot_str(list("original" = final_data, "dummified" = dummify(final_data, maxcat = 5L)), print_network = FALSE),
	width = 800,
	height = 1500,
	fontSize = 20,
	margin = list(
		"left" = 50,
		"right" = 50
	)
)
```

Note the `maxcat` argument. If a discrete feature has more categories than `maxcat`, it will not be dummified. As a result, it will be returned touched.

### Drop features
After viewing the feature distribution, you often want to drop features that are insignificant. For example, features like **dst_dest** has mostly one value, and it doesn't provide any valuable information. You can use `drop_columns` to quickly drop features. The function takes either names or column indices.

```{r fe-drop-columns}
identical(
	drop_columns(final_data, c("dst_dest", "tzone_dest")),
	drop_columns(final_data, c(36, 37))
)
```

## Data Reporting
To organize all the data profiling statistics into a report, you may use the `create_report()` function. It will run most of the EDA functions and output a html file.

```{r dr-create-report, eval=FALSE}
create_report(final_data)
```

To maximize the usage of this function, always supply a response variable (if applicable) to automate various bivariate analyses. For example,

```{r dr-create-report-with-y, eval=FALSE}
create_report(final_data, y = "arr_delay")
```

You may also customize each individual section by passing their corresponding arguments as a list. They will later be passed to `do.call` to be invoked. The default config file is listed below. Simply copy and edit as necessary.

```{r dr-create-report-customize, eval=FALSE}
## Customize report configuration
config <- list(
	"introduce" = list(),
	"plot_str" = list(
		"type" = "diagonal",
		"fontSize" = 35,
		"width" = 1000,
		"margin" = list("left" = 350, "right" = 250)
	),
	"plot_missing" = list(),
	"plot_histogram" = list(),
	"plot_bar" = list(),
	"plot_correlation" = list("use" = "pairwise.complete.obs"),
	"plot_prcomp" = list(),
	"plot_boxplot" = list(),
	"plot_scatterplot" = list()
)
## Create final report
create_report(final_data, y = "arr_delay", config = config)
```
